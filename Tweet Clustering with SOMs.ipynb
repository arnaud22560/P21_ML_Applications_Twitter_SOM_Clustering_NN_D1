{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering tweets about Machine Learning using self-organizing maps\n",
    "\n",
    "*Arnaud Le Doeuff*\n",
    "*Ignacio Dorado*\n",
    "*11/20*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usefull Links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://github.com/RodolfoFerro/pandas_twitter/blob/master/01-extracting-data.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "import tweepy\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Capture the tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Talk about twitter api, credentials and stafff..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from credentials import *    # This will allow us to use the keys as variables\n",
    "\n",
    "# API's setup:\n",
    "def twitter_setup():\n",
    "    \"\"\"\n",
    "    Utility function to setup the Twitter's API\n",
    "    with our access keys provided.\n",
    "    \"\"\"\n",
    "    # Authentication and access using keys:\n",
    "    auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    auth.set_access_token(ACCESS_TOKEN, ACCESS_SECRET)\n",
    "\n",
    "    # Return API with authentication:\n",
    "    api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "    return api\n",
    "\n",
    "# We create an extractor object:\n",
    "extractor = twitter_setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twitter will only allow us to download 3200 tweets every 15 minutes, which is not a lot considering most of them are retweeets. Only 7 days (or so) can be retrieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/search/tweets': {'limit': 180, 'remaining': 180, 'reset': 1605733568}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Words we want to search for\n",
    "searchQuery = \"machine learning\"\n",
    "\n",
    "# Maximum number of tweets we want to collect \n",
    "maxTweets = 100\n",
    "\n",
    "# Show our current limitations\n",
    "extractor.rate_limit_status()['resources']['search']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 100 tweets\n",
      "Kept 14 non RT tweets\n"
     ]
    }
   ],
   "source": [
    "tweetCount = 0\n",
    "global_count = 0\n",
    "# We create a tweet list as follows:\n",
    "tweets=[]\n",
    "#Tell the Cursor method that we want to use the Search API (api.search)\n",
    "#Also tell Cursor our query, and the maximum number of tweets to return\n",
    "for tweet in tweepy.Cursor(extractor.search,q=searchQuery, tweet_mode='extended').items(maxTweets):\n",
    "    \n",
    "    #Verify the tweet has place info before writing (It should, if it got past our place filter)\n",
    "    if not tweet.full_text.startswith(\"RT \"):\n",
    "            tweets.append(tweet)\n",
    "            tweetCount += 1\n",
    "    global_count += 1 \n",
    "    \n",
    "    if (global_count%1000 == 0):\n",
    "        print(\"Downloaded {0} tweets\".format(global_count))\n",
    "        print(\"Kept {0} non RT tweets\".format(tweetCount))\n",
    "    \n",
    "\n",
    "#Display how many tweets we have collected\n",
    "print(\"Downloaded {0} tweets\".format(global_count))\n",
    "print(\"Kept {0} non RT tweets\".format(tweetCount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of tweets: <class 'list'>\n",
      "Type of each tweet: <class 'tweepy.models.Status'>\n"
     ]
    }
   ],
   "source": [
    "print (\"Type of tweets: \" + str(type(tweets)))\n",
    "print (\"Type of each tweet: \" + str(type(tweets[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_api', '_json', 'author', 'contributors', 'coordinates', 'created_at', 'destroy', 'display_text_range', 'entities', 'extended_entities', 'favorite', 'favorite_count', 'favorited', 'full_text', 'geo', 'id', 'id_str', 'in_reply_to_screen_name', 'in_reply_to_status_id', 'in_reply_to_status_id_str', 'in_reply_to_user_id', 'in_reply_to_user_id_str', 'is_quote_status', 'lang', 'metadata', 'parse', 'parse_list', 'place', 'possibly_sensitive', 'retweet', 'retweet_count', 'retweeted', 'retweets', 'source', 'source_url', 'truncated', 'user']\n"
     ]
    }
   ],
   "source": [
    "print(dir(tweets[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>len</th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Source</th>\n",
       "      <th>Likes</th>\n",
       "      <th>RTs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@jeffcannata *eyes \"machine learning limerick generator\"...</td>\n",
       "      <td>65</td>\n",
       "      <td>1329169216805740548</td>\n",
       "      <td>2020-11-18 21:06:50</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The new economy in Arizona requires workers with artific...</td>\n",
       "      <td>302</td>\n",
       "      <td>1329168791075516419</td>\n",
       "      <td>2020-11-18 21:05:09</td>\n",
       "      <td>Sprout Social</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Kirby0Louise Please enlighten me, SAM is not Supersampl...</td>\n",
       "      <td>90</td>\n",
       "      <td>1329168553208131585</td>\n",
       "      <td>2020-11-18 21:04:12</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Machine Learning Pocket Reference: Working with Structur...</td>\n",
       "      <td>114</td>\n",
       "      <td>1329168493837684736</td>\n",
       "      <td>2020-11-18 21:03:58</td>\n",
       "      <td>Postmatico</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5 Ways to Improve User Experience with Machine Learning ...</td>\n",
       "      <td>258</td>\n",
       "      <td>1329168260533727236</td>\n",
       "      <td>2020-11-18 21:03:02</td>\n",
       "      <td>Buffer</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The organizations, which have the impact of exponentiall...</td>\n",
       "      <td>250</td>\n",
       "      <td>1329168252484919303</td>\n",
       "      <td>2020-11-18 21:03:00</td>\n",
       "      <td>Buffer</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pretty interesting. They achieved 3x-7x faster training ...</td>\n",
       "      <td>279</td>\n",
       "      <td>1329168190388269059</td>\n",
       "      <td>2020-11-18 21:02:45</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The way we train AI is fundamentally flawed https://t.co...</td>\n",
       "      <td>276</td>\n",
       "      <td>1329168147493031937</td>\n",
       "      <td>2020-11-18 21:02:35</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Combination of Imaging and Machine Learning Can Predict ...</td>\n",
       "      <td>295</td>\n",
       "      <td>1329167908501483520</td>\n",
       "      <td>2020-11-18 21:01:38</td>\n",
       "      <td>Hootsuite Inc.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://t.co/mHkYKZoC0X, machine learning startup backed...</td>\n",
       "      <td>151</td>\n",
       "      <td>1329167811768414211</td>\n",
       "      <td>2020-11-18 21:01:15</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Starting something vibrant with DSN AI+ FUTA is awesome,...</td>\n",
       "      <td>301</td>\n",
       "      <td>1329167712208232451</td>\n",
       "      <td>2020-11-18 21:00:51</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>UMD Researchers Receive USDA Funding to Use Big Data Ana...</td>\n",
       "      <td>107</td>\n",
       "      <td>1329167649046196228</td>\n",
       "      <td>2020-11-18 21:00:36</td>\n",
       "      <td>Hootsuite Inc.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Happy to talk next Wednesday at the summer school on Com...</td>\n",
       "      <td>275</td>\n",
       "      <td>1329167622898905091</td>\n",
       "      <td>2020-11-18 21:00:30</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>restriction relapses hit fast when you know how to do ma...</td>\n",
       "      <td>97</td>\n",
       "      <td>1329167534738829312</td>\n",
       "      <td>2020-11-18 21:00:09</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         Tweets  len  \\\n",
       "0   @jeffcannata *eyes \"machine learning limerick generator\"...   65   \n",
       "1   The new economy in Arizona requires workers with artific...  302   \n",
       "2   @Kirby0Louise Please enlighten me, SAM is not Supersampl...   90   \n",
       "3   Machine Learning Pocket Reference: Working with Structur...  114   \n",
       "4   5 Ways to Improve User Experience with Machine Learning ...  258   \n",
       "5   The organizations, which have the impact of exponentiall...  250   \n",
       "6   Pretty interesting. They achieved 3x-7x faster training ...  279   \n",
       "7   The way we train AI is fundamentally flawed https://t.co...  276   \n",
       "8   Combination of Imaging and Machine Learning Can Predict ...  295   \n",
       "9   https://t.co/mHkYKZoC0X, machine learning startup backed...  151   \n",
       "10  Starting something vibrant with DSN AI+ FUTA is awesome,...  301   \n",
       "11  UMD Researchers Receive USDA Funding to Use Big Data Ana...  107   \n",
       "12  Happy to talk next Wednesday at the summer school on Com...  275   \n",
       "13  restriction relapses hit fast when you know how to do ma...   97   \n",
       "\n",
       "                     ID                Date               Source  Likes  RTs  \n",
       "0   1329169216805740548 2020-11-18 21:06:50  Twitter for Android      0    0  \n",
       "1   1329168791075516419 2020-11-18 21:05:09        Sprout Social      0    1  \n",
       "2   1329168553208131585 2020-11-18 21:04:12      Twitter Web App      0    0  \n",
       "3   1329168493837684736 2020-11-18 21:03:58           Postmatico      0    1  \n",
       "4   1329168260533727236 2020-11-18 21:03:02               Buffer      0    1  \n",
       "5   1329168252484919303 2020-11-18 21:03:00               Buffer      0    1  \n",
       "6   1329168190388269059 2020-11-18 21:02:45   Twitter for iPhone      0    1  \n",
       "7   1329168147493031937 2020-11-18 21:02:35   Twitter for iPhone      0    2  \n",
       "8   1329167908501483520 2020-11-18 21:01:38       Hootsuite Inc.      0    1  \n",
       "9   1329167811768414211 2020-11-18 21:01:15      Twitter Web App      0    1  \n",
       "10  1329167712208232451 2020-11-18 21:00:51      Twitter Web App      0    1  \n",
       "11  1329167649046196228 2020-11-18 21:00:36       Hootsuite Inc.      0    1  \n",
       "12  1329167622898905091 2020-11-18 21:00:30      Twitter Web App      0    1  \n",
       "13  1329167534738829312 2020-11-18 21:00:09   Twitter for iPhone      0    1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We create a pandas dataframe as follows:\n",
    "df = pd.DataFrame(data=[tweet.full_text for tweet in tweets], columns=['Tweets'])\n",
    "\n",
    "#We add all the information we want to keep about the tweets\n",
    "df['len']  = np.array([len(tweet.full_text) for tweet in tweets])\n",
    "df['ID']   = np.array([tweet.id for tweet in tweets])\n",
    "df['Date'] = np.array([tweet.created_at for tweet in tweets])\n",
    "df['Source'] = np.array([tweet.source for tweet in tweets])\n",
    "df['Likes']  = np.array([tweet.favorite_count for tweet in tweets])\n",
    "df['RTs']    = np.array([tweet.retweet_count for tweet in tweets])\n",
    "\n",
    "# We display the first 10 elements of the dataframe:\n",
    "pd.set_option('display.max_colwidth', 60)\n",
    "display(df.head(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we save the Data Frame it to a csv file so we can read it every time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('tweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"tweets(1171).csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First thing would be to get rid off every comma, point and any other strange symbol\n",
    "    - Discuss if @s should be removed or kept\n",
    "    - Discuss if  hastags should be removed\n",
    "    - Remove symbols that stands on their own\n",
    "    - Remove urls\n",
    "- Second thing would be creating the dictionary\n",
    "- Then reducing the dictionay\n",
    "- Finally do some PCA (probabbly(?))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Original taken from https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"@[^\\s]+\", \" \", string)             #remove account tags   \n",
    "    string = re.sub(r\"http[^\\s]+\", \" \", string)          #remove urls\n",
    "    string = re.sub(r\"#[^\\s]+\", \" \", string)             #remove hastags\n",
    "    string = re.sub(r\"[^A-Za-z\\']\", \" \", string)         #remove everything but letters and nummbers(?)\n",
    "    string = re.sub(r\"\\'s\", \" is\", string)               #split 's contractions\n",
    "    string = re.sub(r\"\\'ve\", \" have\", string)            #split 's contractions\n",
    "    string = re.sub(r\"n\\'t\", \" not\", string)             #split n't contractions\n",
    "    string = re.sub(r\"\\'re\", \" are\", string)             #split 're contractions\n",
    "    string = re.sub(r\"\\'d\", \" would\", string)            #split 'd contractions\n",
    "    string = re.sub(r\"\\'ll\", \" will\", string)            #split 'll contractions\n",
    "    string = re.sub(r\"\\'\", \" \", string)                  #remove '\n",
    "    string = re.sub(r\"!\", \" ! \", string)                 #split !\n",
    "    string = re.sub(r\"\\?\", \" \\? \", string)               #split ?\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)              #remove more than 1 white space\n",
    "    return string.strip().lower()            #remove start and end white spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tweets'] = df['Tweets'].apply(clean_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>len</th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Source</th>\n",
       "      <th>Likes</th>\n",
       "      <th>RTs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eyes machine learning limerick generator project</td>\n",
       "      <td>65</td>\n",
       "      <td>1329169216805740548</td>\n",
       "      <td>2020-11-18 21:06:50</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the new economy in arizona requires workers with artificial intelligence skills our workforce amp economic development officer darcy renfro emphasizes the need for diversity behind the people translating the human mind into machine learning</td>\n",
       "      <td>302</td>\n",
       "      <td>1329168791075516419</td>\n",
       "      <td>2020-11-18 21:05:09</td>\n",
       "      <td>Sprout Social</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>please enlighten me sam is not supersampling by machine learning like dlss</td>\n",
       "      <td>90</td>\n",
       "      <td>1329168553208131585</td>\n",
       "      <td>2020-11-18 21:04:12</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                             Tweets  \\\n",
       "0                                                                                                                                                                                                  eyes machine learning limerick generator project   \n",
       "1  the new economy in arizona requires workers with artificial intelligence skills our workforce amp economic development officer darcy renfro emphasizes the need for diversity behind the people translating the human mind into machine learning   \n",
       "2                                                                                                                                                                        please enlighten me sam is not supersampling by machine learning like dlss   \n",
       "\n",
       "   len                   ID                Date               Source  Likes  \\\n",
       "0   65  1329169216805740548 2020-11-18 21:06:50  Twitter for Android      0   \n",
       "1  302  1329168791075516419 2020-11-18 21:05:09        Sprout Social      0   \n",
       "2   90  1329168553208131585 2020-11-18 21:04:12      Twitter Web App      0   \n",
       "\n",
       "   RTs  \n",
       "0    0  \n",
       "1    1  \n",
       "2    0  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize the clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Discuss the results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
